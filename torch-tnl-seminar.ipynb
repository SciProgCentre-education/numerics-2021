{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "788c31ba",
   "metadata": {},
   "source": [
    "# C++/CUDA extensions for Python\n",
    "\n",
    "## Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64f7cb12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Architecture:                    x86_64\r\n",
      "CPU op-mode(s):                  32-bit, 64-bit\r\n",
      "Byte Order:                      Little Endian\r\n",
      "Address sizes:                   48 bits physical, 48 bits virtual\r\n",
      "CPU(s):                          8\r\n",
      "On-line CPU(s) list:             0-7\r\n",
      "Thread(s) per core:              2\r\n",
      "Core(s) per socket:              4\r\n",
      "Socket(s):                       1\r\n",
      "Vendor ID:                       AuthenticAMD\r\n",
      "CPU family:                      23\r\n",
      "Model:                           24\r\n",
      "Model name:                      AMD Ryzen 7 3750H with Radeon Vega Mobile Gfx\r\n",
      "Stepping:                        1\r\n",
      "CPU MHz:                         2295.612\r\n",
      "BogoMIPS:                        4591.22\r\n",
      "Virtualization:                  AMD-V\r\n",
      "Hypervisor vendor:               Microsoft\r\n",
      "Virtualization type:             full\r\n",
      "L1d cache:                       128 KiB\r\n",
      "L1i cache:                       256 KiB\r\n",
      "L2 cache:                        2 MiB\r\n",
      "L3 cache:                        4 MiB\r\n",
      "Vulnerability Itlb multihit:     Not affected\r\n",
      "Vulnerability L1tf:              Not affected\r\n",
      "Vulnerability Mds:               Not affected\r\n",
      "Vulnerability Meltdown:          Not affected\r\n",
      "Vulnerability Spec store bypass: Mitigation; Speculative Store Bypass disabled v\r\n",
      "                                 ia prctl and seccomp\r\n",
      "Vulnerability Spectre v1:        Mitigation; usercopy/swapgs barriers and __user\r\n",
      "                                  pointer sanitization\r\n",
      "Vulnerability Spectre v2:        Mitigation; Full AMD retpoline, IBPB conditiona\r\n",
      "                                 l, STIBP disabled, RSB filling\r\n",
      "Vulnerability Srbds:             Not affected\r\n",
      "Vulnerability Tsx async abort:   Not affected\r\n",
      "Flags:                           fpu vme de pse tsc msr pae mce cx8 apic sep mtr\r\n",
      "                                 r pge mca cmov pat pse36 clflush mmx fxsr sse s\r\n",
      "                                 se2 ht syscall nx mmxext fxsr_opt pdpe1gb rdtsc\r\n",
      "                                 p lm constant_tsc rep_good nopl tsc_reliable no\r\n",
      "                                 nstop_tsc cpuid extd_apicid pni pclmulqdq ssse3\r\n",
      "                                  fma cx16 sse4_1 sse4_2 movbe popcnt aes xsave \r\n",
      "                                 avx f16c rdrand hypervisor lahf_lm cmp_legacy s\r\n",
      "                                 vm cr8_legacy abm sse4a misalignsse 3dnowprefet\r\n",
      "                                 ch osvw topoext ssbd ibpb vmmcall fsgsbase bmi1\r\n",
      "                                  avx2 smep bmi2 rdseed adx smap clflushopt sha_\r\n",
      "                                 ni xsaveopt xsavec xgetbv1 xsaves clzero xsavee\r\n",
      "                                 rptr virt_ssbd arat npt nrip_save tsc_scale vmc\r\n",
      "                                 b_clean flushbyasid decodeassists pausefilter p\r\n",
      "                                 fthreshold v_vmsave_vmload\r\n"
     ]
    }
   ],
   "source": [
    "!lscpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f94fa98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Feb 18 06:26:31 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 510.47.03    Driver Version: 511.65       CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  On   | 00000000:01:00.0  On |                  N/A |\n",
      "| N/A   50C    P5    12W /  N/A |    295MiB /  6144MiB |      7%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d846b646",
   "metadata": {},
   "source": [
    "*Latency numbers every programmer should know* (Jeff Dean):\n",
    "\n",
    "**L1 cache reference 0.5 ns**\n",
    "\n",
    "**L2 cache reference 7 ns**\n",
    "\n",
    "**Main memory reference 100 ns**\n",
    "\n",
    "![CPUCUDA](https://docs.nvidia.com/cuda/cuda-c-programming-guide/graphics/gpu-devotes-more-transistors-to-data-processing.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff977b18",
   "metadata": {},
   "source": [
    "## PyTorch extensions\n",
    "\n",
    "More info:\n",
    "* [PyTorch C++ tutorial](https://pytorch.org/tutorials/advanced/cpp_extension.html)\n",
    "* [Pybind11 docs](https://pybind11.readthedocs.io/en/stable/basics.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec584dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcc --version\n",
    "!g++ --version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777e4677",
   "metadata": {},
   "source": [
    "### Set-up\n",
    "\n",
    "If you are on Google Colab execute:\n",
    "```\n",
    "!pip install Ninja\n",
    "!add-apt-repository ppa:ubuntu-toolchain-r/test -y\n",
    "!apt update\n",
    "!apt upgrade -y\n",
    "!apt install gcc-9 g++-9\n",
    "!update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-9 100 --slave /usr/bin/g++ g++ /usr/bin/g++-9\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea88842e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch built with:\n",
      "  - GCC 7.3\n",
      "  - C++ Version: 201402\n",
      "  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 10.2\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70\n",
      "  - CuDNN 7.6.5\n",
      "  - Magma 2.5.2\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=10.2, CUDNN_VERSION=7.6.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, \n",
      "\n",
      "ATen/Parallel:\n",
      "\tat::get_num_threads() : 4\n",
      "\tat::get_num_interop_threads() : 4\n",
      "OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "\tomp_get_max_threads() : 4\n",
      "Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\n",
      "\tmkl_get_max_threads() : 4\n",
      "Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)\n",
      "std::thread::hardware_concurrency() : 8\n",
      "Environment variables:\n",
      "\tOMP_NUM_THREADS : [not set]\n",
      "\tMKL_NUM_THREADS : [not set]\n",
      "ATen parallel backend: OpenMP\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.cpp_extension import load\n",
    "print(torch.__config__.show())\n",
    "print(torch.__config__.parallel_info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e366023a",
   "metadata": {},
   "source": [
    "```cpp\n",
    "//cpp_intro.cc file\n",
    "\n",
    "#include <torch/extension.h>\n",
    "\n",
    "torch::Tensor get_rotations(const torch::Tensor &thetas) {\n",
    "    const auto f = thetas.flatten();\n",
    "    const auto n = f.numel();\n",
    "    const auto c = torch::cos(f);\n",
    "    const auto s = torch::sin(f);\n",
    "    return torch::stack({c, -s, s, c}).t().view({n, 2, 2});\n",
    "}\n",
    "\n",
    "PYBIND11_MODULE(TORCH_EXTENSION_NAME, m) {\n",
    "    m.def(\"get_rotations\", &get_rotations, py::call_guard<py::gil_scoped_release>(),\n",
    "          \"Generate 2D rotations given angles thetas\");\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c4b9f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8754a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emitting ninja build file ./build/build.ninja...\n",
      "Building extension module cpp_intro...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "[1/2] c++ -MMD -MF cpp_intro.o.d -DTORCH_EXTENSION_NAME=cpp_intro -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -isystem /home/rolan/miniconda3/envs/noa/lib/python3.9/site-packages/torch/include -isystem /home/rolan/miniconda3/envs/noa/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -isystem /home/rolan/miniconda3/envs/noa/lib/python3.9/site-packages/torch/include/TH -isystem /home/rolan/miniconda3/envs/noa/lib/python3.9/site-packages/torch/include/THC -isystem /home/rolan/miniconda3/envs/noa/include/python3.9 -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++14 -Wall -Wextra -Wpedantic -O3 -std=c++17 -c /home/rolan/devspace/numerics-2021/cpp_intro.cc -o cpp_intro.o \n",
      "[2/2] c++ cpp_intro.o -shared -L/home/rolan/miniconda3/envs/noa/lib/python3.9/site-packages/torch/lib -lc10 -ltorch_cpu -ltorch -ltorch_python -o cpp_intro.so\n",
      "Loading extension module cpp_intro...\n"
     ]
    }
   ],
   "source": [
    "cpp_intro = load(name='cpp_intro',\n",
    "             build_directory='./build',\n",
    "             sources=['cpp_intro.cc'],\n",
    "             extra_cflags=['-Wall -Wextra -Wpedantic -O3 -std=c++17'],\n",
    "             verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "230ae24e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.0000,  0.0089],\n",
       "         [-0.0089,  1.0000]],\n",
       "\n",
       "        [[ 0.9996, -0.0287],\n",
       "         [ 0.0287,  0.9996]],\n",
       "\n",
       "        [[ 0.9976, -0.0700],\n",
       "         [ 0.0700,  0.9976]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 3\n",
    "PI = 2. * torch.acos(torch.tensor(0.))\n",
    "thetas = 0.05 * PI * (torch.rand(N) - 0.5) # example of angles in radians\n",
    "rots = cpp_intro.get_rotations(thetas)\n",
    "rots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9e08b72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(8.4294e-08)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.dist(rots.matmul(rots.transpose(-1,-2)), torch.eye(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91bb984e",
   "metadata": {},
   "source": [
    "## Heterogeneous computing with TNL \n",
    "\n",
    "Tutorials worth working through include: \n",
    "* [TNL tutorials](https://mmg-gitlab.fjfi.cvut.cz/doc/tnl/md_Tutorials_index.html#Tutorials)\n",
    "* [CUDA made easy](https://developer.nvidia.com/blog/even-easier-introduction-cuda)\n",
    "* [CUDA guide](https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3bda9abf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "643c72eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\r\n",
      "Copyright (c) 2005-2021 NVIDIA Corporation\r\n",
      "Built on Fri_Dec_17_18:16:03_PST_2021\r\n",
      "Cuda compilation tools, release 11.6, V11.6.55\r\n",
      "Build cuda_11.6.r11.6/compiler.30794723_0\r\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f592f779",
   "metadata": {},
   "source": [
    "![multithreading](https://randu.org/tutorials/threads/images/process.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346bc986",
   "metadata": {},
   "source": [
    "![sm](https://docs.nvidia.com/cuda/cuda-c-programming-guide/graphics/automatic-scalability.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0402a92",
   "metadata": {},
   "source": [
    "![blocks](https://docs.nvidia.com/cuda/cuda-c-programming-guide/graphics/grid-of-thread-blocks.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ce9378",
   "metadata": {},
   "source": [
    "![CUDA](https://developer-blogs.nvidia.com/wp-content/uploads/2017/01/cuda_indexing.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1aee565",
   "metadata": {},
   "source": [
    "A [TNL](https://mmg-gitlab.fjfi.cvut.cz/gitlab/tnl/tnl-dev) version compatible with PyTorch is also available as third-party library within [NOA](https://github.com/grinisrit/noa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d677a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/grinisrit/noa.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0260a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "noa_location = 'noa'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "993bfc41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emitting ninja build file ./build/build.ninja...\n",
      "Building extension module tnl_intro...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "[1/2] c++ -MMD -MF tnl-intro.o.d -DTORCH_EXTENSION_NAME=tnl_intro -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -I/home/rolan/devspace/numerics-2021/noa/src -I/home/rolan/devspace/numerics-2021 -isystem /home/rolan/miniconda3/envs/noa/lib/python3.9/site-packages/torch/include -isystem /home/rolan/miniconda3/envs/noa/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -isystem /home/rolan/miniconda3/envs/noa/lib/python3.9/site-packages/torch/include/TH -isystem /home/rolan/miniconda3/envs/noa/lib/python3.9/site-packages/torch/include/THC -isystem /home/rolan/miniconda3/envs/noa/include/python3.9 -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++14 -O3 -std=c++17 -fopenmp -c /home/rolan/devspace/numerics-2021/tnl-intro.cc -o tnl-intro.o \n",
      "[2/2] c++ tnl-intro.o -shared -L/home/rolan/miniconda3/envs/noa/lib/python3.9/site-packages/torch/lib -lc10 -ltorch_cpu -ltorch -ltorch_python -o tnl_intro.so\n",
      "Loading extension module tnl_intro...\n"
     ]
    }
   ],
   "source": [
    "tnl_intro = load(name='tnl_intro',\n",
    "             build_directory='./build',\n",
    "             sources=['tnl-intro.cc'],\n",
    "             extra_include_paths=[f'{noa_location}/src', '.'],    \n",
    "             extra_cflags=['-O3 -std=c++17 -fopenmp'],\n",
    "             verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b166da06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file ./build/build.ninja...\n",
      "Building extension module tnl_intro_cuda...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "ninja: no work to do.\n",
      "Loading extension module tnl_intro_cuda...\n"
     ]
    }
   ],
   "source": [
    "tnl_intro_cuda = load(name='tnl_intro_cuda',\n",
    "             build_directory='./build',\n",
    "             sources=['tnl-intro.cu'],\n",
    "             extra_include_paths=[f'{noa_location}/src', '.'],    \n",
    "             extra_cflags=['-O3 -std=c++17'],\n",
    "             extra_cuda_cflags=['-std=c++17 --expt-relaxed-constexpr --expt-extended-lambda'],\n",
    "             verbose=True)  if torch.cuda.is_available() else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8352d016",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.randn(10000000)\n",
    "t_cuda = t.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a54cc69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-953.7388916015625"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tnl_intro.map_reduce(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "06a92de7",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CPU tensor required",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_180/46267507.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtnl_intro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_reduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_cuda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: CPU tensor required"
     ]
    }
   ],
   "source": [
    "tnl_intro.map_reduce(t_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f928e1bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-953.7645263671875"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tnl_intro_cuda.map_reduce(t_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "975eb28b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.29 ms ± 222 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit tnl_intro.map_reduce(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eccc4d38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "457 µs ± 22.5 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit tnl_intro_cuda.map_reduce(t_cuda)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
